import requests
from bs4 import BeautifulSoup
from utils.db_utils import insert_fact, get_existing_urls
from datetime import datetime

CONGRESS_URL = "https://www.congress.gov/news"

def scrape_congress():
    existing_urls = get_existing_urls("congress")
    response = requests.get(CONGRESS_URL, timeout=10)
    soup = BeautifulSoup(response.text, "html.parser")

    for item in soup.select("li.item"):
        link_tag = item.find("a")
        if not link_tag:
            continue
        link = link_tag["href"]
        if link in existing_urls:
            continue

        title = link_tag.text.strip()
        date_tag = item.find("span.date")
        date = date_tag.text.strip() if date_tag else datetime.now().isoformat()
        content = item.get_text(separator=" ", strip=True)

        insert_fact("congress", title, link, date, content)
