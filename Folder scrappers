import requests
from bs4 import BeautifulSoup
from utils.db_utils import insert_fact, get_existing_urls
from datetime import datetime

WHITE_HOUSE_URL = "https://www.whitehouse.gov/briefing-room/"

def scrape_white_house():
    existing_urls = get_existing_urls("white_house")
    response = requests.get(WHITE_HOUSE_URL, timeout=10)
    soup = BeautifulSoup(response.text, "html.parser")

    for article in soup.find_all("article"):
        link_tag = article.find("a")
        if not link_tag:
            continue
        link = link_tag["href"]
        if link in existing_urls:
            continue

        title_tag = article.find("h2")
        title = title_tag.text.strip() if title_tag else "No Title"
        date_tag = article.find("time")
        date = date_tag["datetime"] if date_tag else datetime.now().isoformat()
        content = article.get_text(separator=" ", strip=True)

        insert_fact("white_house", title, link, date, content)
